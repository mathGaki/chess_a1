# src/mcts.py
import numpy as np
import torch
import math
import copy
from .utils import move_to_policy_index, policy_index_to_move, position_to_tensor, position_to_tensor_cached
from .config import (ACTION_SPACE_SIZE, MCTS_DIRICHLET_ALPHA, MCTS_DIRICHLET_WEIGHT, 
                     MCTS_TEMPERATURE_EARLY, MCTS_TEMPERATURE_LATE, MCTS_TEMPERATURE_THRESHOLD,
                     MCTS_C_PUCT)
from ..core.constants import start_position
from ..core.moves import make_move

class Node:
    """MCTS íŠ¸ë¦¬ì˜ ë…¸ë“œ (ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „)"""
    __slots__ = ['parent', 'children', 'visit_count', 'total_action_value', 
                 'mean_action_value', 'prior_p', 'position']
    
    def __init__(self, parent, prior_p, position=None):
        self.parent = parent
        self.children = {}  # {move: Node}
        self.visit_count = 0
        self.total_action_value = 0.0
        self.mean_action_value = 0.0
        self.prior_p = prior_p
        self.position = position # ì´ ë…¸ë“œê°€ ë‚˜íƒ€ë‚´ëŠ” ê²Œì„ ìƒíƒœ

    def select(self, c_puct, logger=None, depth=0):
        """UCT(PUCT) ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìì‹ ë…¸ë“œ ì„ íƒ (ìµœì í™”ëœ ë²„ì „)"""
        if not self.children:
            return None, None
            
        best_score = -float('inf')
        best_move = None
        best_child = None

        # ì œê³±ê·¼ ë¯¸ë¦¬ ê³„ì‚° (ë°˜ë³µ ê³„ì‚° ë°©ì§€)
        sqrt_parent_visits = math.sqrt(self.visit_count)
        c_puct_sqrt = c_puct * sqrt_parent_visits  # ê³µí†µ ê³„ì‚° ë¯¸ë¦¬ ìˆ˜í–‰
        
        # ìµœì í™”ëœ ë°˜ë³µë¬¸ (ì•ˆì „ì„± ì²´í¬ í¬í•¨)
        for move, child in self.children.items():
            # ì•ˆì „ì„± ì²´í¬: positionì´ Noneì¸ ìì‹ ë…¸ë“œëŠ” ê±´ë„ˆëœ€
            if child.position is None:
                continue
                
            # UCT ì ìˆ˜ ê³„ì‚° (AlphaZero PUCT ê³µì‹) - ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼
            if child.visit_count == 0:
                # ë¯¸ë°©ë¬¸ ë…¸ë“œ: P(s,a) * c_puct * sqrt(N(s))
                uct_score = child.prior_p * c_puct_sqrt
            else:
                # ë°©ë¬¸ëœ ë…¸ë“œ: Q(s,a) + P(s,a) * c_puct * sqrt(N(s)) / (1 + N(s,a))
                uct_score = child.mean_action_value + (child.prior_p * c_puct_sqrt) / (1 + child.visit_count)
            
            if uct_score > best_score:
                best_score = uct_score
                best_move = move
                best_child = child

        return best_move, best_child

    def expand(self, legal_moves, policy):
        """
        ë¦¬í”„ ë…¸ë“œë¥¼ í™•ì¥. ìì‹ ë…¸ë“œë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        AlphaZero ë…¼ë¬¸ (Methods -> Search)ì— ë”°ë¼, ì‹ ê²½ë§ì˜ ì •ì±…(p)ì„ ì‚¬ìš©í•˜ì—¬
        ê° ìœ íš¨í•œ ìˆ˜ì— ëŒ€í•œ ì‚¬ì „ í™•ë¥ ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            legal_moves: í•©ë²•ìˆ˜ ë¦¬ìŠ¤íŠ¸
            policy: í•©ë²•ìˆ˜ì— ëŒ€ì‘í•˜ëŠ” ì •ì±… í™•ë¥  ë°°ì—´ (len(legal_moves)ì™€ ê°™ì€ í¬ê¸°)
        """
        
        for i, move in enumerate(legal_moves):
            if move not in self.children:
                # policyëŠ” í•©ë²•ìˆ˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ í™•ë¥  ë°°ì—´
                try:
                    prior_prob = policy[i].item() if isinstance(policy, torch.Tensor) else policy[i]
                except IndexError:
                    print(f"Policy index {i} out of bounds (policy size: {len(policy)}, legal_moves: {len(legal_moves)})")
                    prior_prob = 1.0 / len(legal_moves)  # ê· ë“± ë¶„í¬ë¡œ ê¸°ë³¸ê°’
                
                # ìì‹ ë…¸ë“œì˜ positionì€ í˜„ì¬ ë…¸ë“œì˜ positionì— í•´ë‹¹ moveë¥¼ ì ìš©í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
                next_position = make_move(self.position, move)
                
                # make_moveê°€ Noneì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° (ë¶ˆë²•ìˆ˜) ìì‹ ë…¸ë“œë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ
                if next_position is not None:
                    self.children[move] = Node(parent=self, prior_p=prior_prob, position=next_position)
                # make_moveê°€ Noneì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ (ë¶ˆë²•ìˆ˜)
    
    def backpropagate(self, value):
        """
        ë¦¬í”„ ë…¸ë“œì˜ í‰ê°€ê°’(value)ì„ ë£¨íŠ¸ê¹Œì§€ ì—­ì „íŒŒí•©ë‹ˆë‹¤. (ìµœì í™”ëœ ë²„ì „)
        """
        node = self
        while node is not None:
            node.visit_count += 1
            node.total_action_value += value
            node.mean_action_value = node.total_action_value / node.visit_count
            node = node.parent
            value = -value  # AlphaZero: ìƒëŒ€ë°© ì‹œì ìœ¼ë¡œ ë³€í™˜
    
    def is_fully_expanded(self):
        """
        ë…¸ë“œê°€ ì™„ì „íˆ í™•ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        return len(self.children) > 0 if self.position is not None else True
    
    def is_leaf(self):
        """ë¦¬í”„ ë…¸ë“œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return len(self.children) == 0

class MCTS:
    """ëª¬í…Œì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰ í´ë˜ìŠ¤"""
    def __init__(self, c_puct=None):
        self.c_puct = c_puct if c_puct is not None else MCTS_C_PUCT
        self.root = None

    def search(self, position, move_generator, num_simulations, req_q, resp_q, worker_id, move_count=0, logger=None, temperature=1.0, add_dirichlet_noise=True, dirichlet_alpha=None):
        """
        MCTS íƒìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ë‹¤ìŒ ìˆ˜ë¥¼ ê²°ì •í•˜ê³  ì •ì±… íƒ€ê²Ÿì„ ìƒì„±í•©ë‹ˆë‹¤.
        AlphaZero ë…¼ë¬¸ (Methods -> Search)ì˜ MCTS ê³¼ì •ì„ ë”°ë¦…ë‹ˆë‹¤.
        
        Args:
            position (Position): í˜„ì¬ ê²Œì„ ìƒíƒœ.
            move_generator (function): í˜„ì¬ ìƒíƒœì—ì„œ ê°€ëŠ¥í•œ ìœ íš¨í•œ ìˆ˜ë“¤ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
                                       (ì˜ˆ: legal_moves = move_generator(current_position))
            num_simulations (int): ìˆ˜í–‰í•  ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜.
            req_q (Queue): ì‹ ê²½ë§ í‰ê°€ ìš”ì²­ì„ ë³´ë‚´ëŠ” í. (worker_id, request_id, tensor)
            resp_q (Queue): ì‹ ê²½ë§ í‰ê°€ ì‘ë‹µì„ ë°›ëŠ” í. (worker_id, request_id, policy, value)
            worker_id (int): í˜„ì¬ MCTS ì›Œì»¤ì˜ ID.
            move_count (int): í˜„ì¬ ìˆ˜ ë²ˆí˜¸.
            logger: ë¡œê±° (ì„ íƒì‚¬í•­).
            temperature (float): ìˆ˜ ì„ íƒ ì‹œ ì˜¨ë„ ë§¤ê°œë³€ìˆ˜ (ê¸°ë³¸ê°’: 1.0).
            add_dirichlet_noise (bool): ë£¨íŠ¸ì—ì„œ Dirichlet noise ì¶”ê°€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True).
        
        Returns:
            tuple: (best_move, policy_target)
                   best_move: íƒìƒ‰ ê²°ê³¼ ê°€ì¥ ì¢‹ì€ ìˆ˜.
                   policy_target: ê° ìˆ˜ì˜ ë°©ë¬¸ íšŸìˆ˜ ë¶„í¬ (ì‹ ê²½ë§ í•™ìŠµì„ ìœ„í•œ íƒ€ê²Ÿ).
        """
        # ë£¨íŠ¸ ë…¸ë“œ ìƒì„± ë° ì´ˆê¸° í‰ê°€ ìš”ì²­ (ìºì‹œëœ í…ì„œ ì‚¬ìš©)
        # ë£¨íŠ¸ ë…¸ë“œëŠ” í˜„ì¬ ê²Œì„ ìƒíƒœë¥¼ ê°€ì§€ê³  ì‹œì‘í•©ë‹ˆë‹¤.
        root_tensor = position_to_tensor_cached(position)
        
        req_q.put((worker_id, 0, root_tensor))
        
        # ë£¨íŠ¸ í‰ê°€ ì‘ë‹µ ëŒ€ê¸°
        policy, value = self._wait_for_response(0, resp_q, worker_id)
        
        legal_moves = move_generator(position)
        
        # ë£¨íŠ¸ ë…¸ë“œì˜ prior_pëŠ” ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì˜ë¯¸ ì—†ëŠ” ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        self.root = Node(parent=None, prior_p=0, position=position)
        
        # í•©ë²•ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ì •ì±… í™•ë¥ ë§Œ ì¶”ì¶œ
        legal_move_policies = []
        for move in legal_moves:
            try:
                move_idx = move_to_policy_index(move, position.side)
                prob = policy[move_idx].item() if isinstance(policy, torch.Tensor) else policy[move_idx]
                legal_move_policies.append(prob)
            except Exception as e:
                print(f"Error extracting policy for move {move}: {e}")
                legal_move_policies.append(1.0 / len(legal_moves))  # ê· ë“± ë¶„í¬
        
        # ì •ê·œí™” (í™•ë¥ ì˜ í•©ì´ 1ì´ ë˜ë„ë¡)
        if len(legal_move_policies) > 0:
            policy_sum = sum(legal_move_policies)
            if policy_sum > 0:
                legal_move_policies = [p / policy_sum for p in legal_move_policies]
            else:
                legal_move_policies = [1.0 / len(legal_move_policies) for _ in legal_move_policies]
        
        # AlphaZero: ë£¨íŠ¸ì—ì„œë§Œ Dirichlet noise ì¶”ê°€ (ì¡°ê±´ë¶€)
        if add_dirichlet_noise:
            alpha = dirichlet_alpha if dirichlet_alpha is not None else MCTS_DIRICHLET_ALPHA
            noise = np.random.dirichlet([alpha] * len(legal_move_policies))
            noise_weight = MCTS_DIRICHLET_WEIGHT
            legal_move_policies_with_noise = (1 - noise_weight) * np.array(legal_move_policies) + noise_weight * noise
        else:
            legal_move_policies_with_noise = legal_move_policies
        
        self.root.expand(legal_moves, legal_move_policies_with_noise)
        self.root.backpropagate(value.item())

        # ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ (ìˆœìˆ˜ AlphaZero ë°©ì‹)
        for i in range(1, num_simulations + 1):
            node = self.root
            path = [node] # íƒìƒ‰ ê²½ë¡œë¥¼ ì €ì¥í•˜ì—¬ ì—­ì „íŒŒì— ì‚¬ìš©

            # 1. Select: PUCTë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬í”„ ë…¸ë“œê¹Œì§€ íƒìƒ‰ (ìˆœìˆ˜ AlphaZero)
            depth = 0
            while not node.is_leaf():
                move, node = node.select(self.c_puct, None, depth)
                
                # selectê°€ Noneì„ ë°˜í™˜í•˜ë©´ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ë‹¨
                if move is None or node is None:
                    print(f"Warning: select() returned None in simulation {i}, depth {depth}")
                    break
                    
                path.append(node)
                depth += 1
            
            # ë¦¬í”„ ë…¸ë“œì˜ ê²Œì„ ìƒíƒœ (sim_pos)
            # pathì˜ ë§ˆì§€ë§‰ ë…¸ë“œê°€ í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ì˜ ë¦¬í”„ ë…¸ë“œì´ë¯€ë¡œ, í•´ë‹¹ ë…¸ë“œì˜ positionì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            sim_pos = node.position 
            
            # None position ì²´í¬
            if sim_pos is None:
                print(f"Warning: sim_pos is None in MCTS simulation {i}")
                continue
            
            # 2. Expand & Evaluate: ë¦¬í”„ ë…¸ë“œ í™•ì¥ ë° ì‹ ê²½ë§ í‰ê°€ ìš”ì²­ (ìºì‹œëœ í…ì„œ ì‚¬ìš©)
            # ë¦¬í”„ ë…¸ë“œì˜ ìƒíƒœë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì‹ ê²½ë§ì— í‰ê°€ ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
            leaf_pos_tensor = position_to_tensor_cached(sim_pos) 
            req_q.put((worker_id, i, leaf_pos_tensor))
            
            # 3. Backpropagate (ì‘ë‹µ ëŒ€ê¸° í›„): ì‹ ê²½ë§ í‰ê°€ ê²°ê³¼ë¡œ ì—­ì „íŒŒ
            policy, value = self._wait_for_response(i, resp_q, worker_id)
            
            # ë¦¬í”„ ë…¸ë“œì—ì„œ ê°€ëŠ¥í•œ ìœ íš¨í•œ ìˆ˜ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
            legal_moves_at_leaf = move_generator(sim_pos)
            
            # í•©ë²•ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ì •ì±… í™•ë¥ ë§Œ ì¶”ì¶œ
            legal_move_policies = []
            for move in legal_moves_at_leaf:
                try:
                    move_idx = move_to_policy_index(move, sim_pos.side)
                    prob = policy[move_idx].item() if isinstance(policy, torch.Tensor) else policy[move_idx]
                    legal_move_policies.append(prob)
                except Exception as e:
                    print(f"Error extracting policy for move {move}: {e}")
                    legal_move_policies.append(1.0 / len(legal_moves_at_leaf))  # ê· ë“± ë¶„í¬
            
            # ì •ê·œí™” (í™•ë¥ ì˜ í•©ì´ 1ì´ ë˜ë„ë¡)
            if len(legal_move_policies) > 0:
                policy_sum = sum(legal_move_policies)
                if policy_sum > 0:
                    legal_move_policies = [p / policy_sum for p in legal_move_policies]
                else:
                    legal_move_policies = [1.0 / len(legal_move_policies) for _ in legal_move_policies]
            
            node.expand(legal_moves_at_leaf, legal_move_policies) # ë¦¬í”„ ë…¸ë“œ í™•ì¥ (í•©ë²•ìˆ˜ ì •ì±…ë§Œ ì „ë‹¬)
            node.backpropagate(value.item()) # í‰ê°€ê°’ ì—­ì „íŒŒ

        # íƒìƒ‰ ì™„ë£Œ í›„ ë£¨íŠ¸ì˜ ë°©ë¬¸ íšŸìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ìˆ˜ ì„ íƒ
        move_counts = []
        moves = []
        move_scores = []  # UCT ì ìˆ˜ ê¸°ë¡ì„ ìœ„í•´ ì¶”ê°€
        
        for move, child in self.root.children.items():
            moves.append(move)
            move_counts.append(child.visit_count)
            # ì¼ê´€ëœ UCT ì ìˆ˜ ê³„ì‚° (select ë©”ì„œë“œì™€ ë™ì¼í•œ ë¡œì§)
            sqrt_parent_visits = math.sqrt(self.root.visit_count)
            
            if child.visit_count == 0:
                # ë¯¸ë°©ë¬¸ ë…¸ë“œ: prior_pë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
                uct_score = self.c_puct * child.prior_p * sqrt_parent_visits
            else:
                q_value = child.mean_action_value
                u_value = self.c_puct * child.prior_p * sqrt_parent_visits / (1 + child.visit_count)
                uct_score = q_value + u_value
                
            move_scores.append(uct_score)
        
        if not moves:
            print(f"Warning: No moves available from root!")
            return None, torch.zeros(ACTION_SPACE_SIZE, dtype=torch.float32)
        
        # AlphaZero ë°©ì‹: ì˜¨ë„ ê¸°ë°˜ ì„ íƒ (ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)
        if temperature == 0.0:
            # íƒìš•ì  ì„ íƒ (ê°€ì¥ ë§ì´ ë°©ë¬¸ëœ ìˆ˜)
            best_move = max(self.root.children.items(), key=lambda item: item[1].visit_count)[0]
            selected_idx = moves.index(best_move)
            selection_reason = "greedy (temp=0)"
        else:
            # ì˜¨ë„ ê¸°ë°˜ í™•ë¥ ì  ì„ íƒ
            move_probs = np.array(move_counts, dtype=np.float64)
            
            # AlphaZero ë…¼ë¬¸ì˜ ì˜¨ë„ ê³µì‹: Ï€(a) âˆ N(s,a)^(1/Ï„)
            move_probs = move_probs ** (1.0 / temperature)
            move_probs = move_probs / np.sum(move_probs)
            
            # í™•ë¥ ì  ì„ íƒ (AlphaZero ë°©ì‹)
            selected_idx = np.random.choice(len(moves), p=move_probs)
            best_move = moves[selected_idx]
            selection_reason = f"temperature-based (temp={temperature:.2f})"
        
        # ë””ë²„ê·¸ ë¡œê·¸ (í‰ê°€ ëª¨ë“œì—ì„œë§Œ)
        if temperature == 0.0:  # í‰ê°€ ëª¨ë“œ
            # ìƒìœ„ 3ê°œ ìˆ˜ì˜ ë°©ë¬¸ íšŸìˆ˜ í‘œì‹œ
            move_visit_pairs = list(zip(moves, move_counts))
            move_visit_pairs.sort(key=lambda x: x[1], reverse=True)
            top_moves = move_visit_pairs[:3]
            top_moves_str = ", ".join([f"{move}({visits})" for move, visits in top_moves])
            print(f"  MCTS worker {worker_id}: {num_simulations} sims, selected {selection_reason}")
            print(f"    Top moves: {top_moves_str}, selected: {best_move}({move_counts[selected_idx]})")
            
            # ì „ì²´ ë°©ë¬¸ ë¶„í¬ (ë°©ë¬¸ íšŸìˆ˜ > 0ì¸ ìˆ˜ë“¤ë§Œ)
            visited_moves = [(move, count) for move, count in zip(moves, move_counts) if count > 0]
            if len(visited_moves) > 1:
                print(f"    Total visited moves: {len(visited_moves)}/{len(moves)}")
            else:
                print(f"    Warning: Only {len(visited_moves)} moves visited out of {len(moves)} legal moves!")
        
        # ì •ì±… íƒ€ê²Ÿ ìƒì„± (ë°©ë¬¸ íšŸìˆ˜ ë¶„í¬)
        # ì‹ ê²½ë§ í•™ìŠµì„ ìœ„í•œ íƒ€ê²Ÿìœ¼ë¡œ, ë£¨íŠ¸ ë…¸ë“œì˜ ìì‹ ë°©ë¬¸ íšŸìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ì±… ë¶„í¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        policy_target = torch.zeros(ACTION_SPACE_SIZE, dtype=torch.float32) 
        total_visits = sum(child.visit_count for child in self.root.children.values())
        
        if total_visits > 0:
            for move, child in self.root.children.items():
                move_idx = move_to_policy_index(move, self.root.position.side) 
                policy_target[move_idx] = child.visit_count / total_visits

        return best_move, policy_target

    def search_simple_batch(self, position, move_generator, num_simulations, req_q, resp_q, worker_id, move_count, logger=None, 
                           temperature=None, add_dirichlet_noise=True, dirichlet_alpha=None):
        """
        í•˜ë‚˜ì˜ ë°°ì¹˜ ë©”ì‹œì§€ë¡œ ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ì„ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ (ë””ë²„ê¹… ëª¨ë“œ)
        """
        # print(f"ğŸ” Worker {worker_id}: Starting MCTS with {num_simulations} simulations")
        
        # 1. ë£¨íŠ¸ ë…¸ë“œ ì´ˆê¸°í™”
        root_tensor = position_to_tensor_cached(position)
        # print(f"ğŸ” Worker {worker_id}: Sending root request")
        req_q.put((worker_id, "root", root_tensor))
        
        # print(f"ğŸ” Worker {worker_id}: Waiting for root response")
        policy, value = self._wait_for_batch_response("root", resp_q, worker_id)
        # print(f"ğŸ” Worker {worker_id}: Got root response, policy shape: {policy.shape}, value: {value.item()}")
        
        legal_moves = move_generator(position)
        # print(f"ğŸ” Worker {worker_id}: Found {len(legal_moves)} legal moves")
        
        self.root = Node(parent=None, prior_p=0, position=position)
        
        # ë£¨íŠ¸ í™•ì¥
        legal_move_policies = self._extract_legal_policies(legal_moves, policy, position.side)
        if add_dirichlet_noise:
            legal_move_policies = self._add_dirichlet_noise(legal_move_policies, dirichlet_alpha)
        
        self.root.expand(legal_moves, legal_move_policies)
        self.root.backpropagate(value.item())
        # print(f"ğŸ” Worker {worker_id}: Root expanded with {len(self.root.children)} children")
        
        # 2. ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ì˜ ë¦¬í”„ ë…¸ë“œë¥¼ ë¯¸ë¦¬ ìˆ˜ì§‘ (ìµœì í™”ëœ ë²„ì „)
        all_leaf_nodes = []
        all_leaf_paths = []
        
        # ìµœì í™”: ë°˜ë³µ íƒìƒ‰ì„ ìœ„í•œ ìºì‹œëœ ë³€ìˆ˜ë“¤
        max_depth = 200  # ë¬´í•œ ë£¨í”„ ë°©ì§€
        
        for sim_idx in range(num_simulations):
            # ê° ì‹œë®¬ë ˆì´ì…˜ì˜ ë¦¬í”„ ë…¸ë“œê¹Œì§€ íƒìƒ‰ (ìµœì í™”ëœ ë²„ì „)
            path = []
            current = self.root
            depth = 0
            
            # ìµœì í™”ëœ íƒìƒ‰ ë£¨í”„
            while current.children and depth < max_depth:
                move, next_node = current.select(self.c_puct)
                if next_node is None:
                    break
                current = next_node
                path.append(current)
                depth += 1
            
            # ìœ íš¨í•œ ë…¸ë“œë§Œ ì¶”ê°€ (None ì²´í¬ ìµœì†Œí™”)
            if current.position is not None:
                all_leaf_nodes.append(current)
                all_leaf_paths.append(path)
        
        # ë°°ì¹˜ íš¨ìœ¨ì„± ì²´í¬ (ìµœì í™”ëœ ë²„ì „)
        collected_count = len(all_leaf_nodes)
        if collected_count < num_simulations * 0.8:  # 80% ë¯¸ë§Œì´ë©´ ê²½ê³ 
            efficiency = collected_count / num_simulations * 100
            print(f"âš ï¸ Worker {worker_id}: Low batch efficiency - {collected_count}/{num_simulations} simulations ({efficiency:.1f}%)")
        
        # 3. ëª¨ë“  ë¦¬í”„ ë…¸ë“œë¥¼ í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ ë¬¶ì–´ì„œ ì „ì†¡
        if all_leaf_nodes:
            batch_size = len(all_leaf_nodes)
            # print(f"ğŸ” Worker {worker_id}: Sending batch message with {batch_size} tensors")
            
            # ëª¨ë“  í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì„œ í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¡œ ì „ì†¡
            batch_tensors = []
            for i, node in enumerate(all_leaf_nodes):
                leaf_tensor = position_to_tensor_cached(node.position)
                batch_tensors.append(leaf_tensor)
                # print(f"ğŸ” Worker {worker_id}: Added tensor {i}, shape: {leaf_tensor.shape}")
            
            # í•˜ë‚˜ì˜ ë°°ì¹˜ ë©”ì‹œì§€ë¡œ ì „ì†¡
            # print(f"ğŸ” Worker {worker_id}: Putting batch request in queue")
            req_q.put((worker_id, "batch", batch_tensors))
            
            # í•˜ë‚˜ì˜ ë°°ì¹˜ ì‘ë‹µ ë°›ê¸°
            # print(f"ğŸ” Worker {worker_id}: Waiting for batch response")
            batch_policies, batch_values = self._wait_for_batch_response("batch", resp_q, worker_id)
            # print(f"ğŸ” Worker {worker_id}: Got batch response: {len(batch_policies)} policies, {len(batch_values)} values")
            
            # 4. ê²°ê³¼ ì ìš© ë° ì—­ì „íŒŒ
            for i, (node, path) in enumerate(zip(all_leaf_nodes, all_leaf_paths)):
                if i < len(batch_policies):
                    policy = batch_policies[i]
                    value = batch_values[i].item()
                    
                    # ë…¸ë“œ í™•ì¥
                    legal_moves = move_generator(node.position)
                    legal_policies = self._extract_legal_policies(legal_moves, policy, node.position.side)
                    node.expand(legal_moves, legal_policies)
                    
                    # ì—­ì „íŒŒ
                    node.backpropagate(value)
                else:
                    # ì‘ë‹µì´ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    print(f"ğŸ” Worker {worker_id}: Missing response for simulation {i}, using default")
                    node.backpropagate(0.0)
            
            # print(f"ğŸ” Worker {worker_id}: Processed {len(batch_policies)}/{batch_size} simulations")
        
        # 5. ê²°ê³¼ ë°˜í™˜
        # print(f"ğŸ” Worker {worker_id}: Selecting best move")
        result = self._select_best_move(temperature, move_count)
        # print(f"ğŸ” Worker {worker_id}: Selected move: {result[0]}")
        return result
    
    def _extract_legal_policies(self, legal_moves, policy, side):
        """í•©ë²•ìˆ˜ì— ëŒ€í•œ ì •ì±… í™•ë¥  ì¶”ì¶œ"""
        legal_policies = []
        for move in legal_moves:
            try:
                move_idx = move_to_policy_index(move, side)
                prob = policy[move_idx].item() if isinstance(policy, torch.Tensor) else policy[move_idx]
                legal_policies.append(prob)
            except:
                legal_policies.append(1.0 / len(legal_moves))
        
        # ì •ê·œí™”
        policy_sum = sum(legal_policies)
        if policy_sum > 0:
            legal_policies = [p / policy_sum for p in legal_policies]
        else:
            legal_policies = [1.0 / len(legal_policies) for _ in legal_policies]
        
        return legal_policies
    
    def _add_dirichlet_noise(self, policies, dirichlet_alpha):
        """ë””ë¦¬í´ë ˆ ë…¸ì´ì¦ˆ ì¶”ê°€"""
        alpha = dirichlet_alpha if dirichlet_alpha is not None else MCTS_DIRICHLET_ALPHA
        noise = np.random.dirichlet([alpha] * len(policies))
        noise_weight = MCTS_DIRICHLET_WEIGHT
        return (1 - noise_weight) * np.array(policies) + noise_weight * noise
    
    def _select_best_move(self, temperature, move_count):
        """ìµœì  ìˆ˜ ì„ íƒ"""
        if temperature is None:
            temperature = MCTS_TEMPERATURE_EARLY if move_count < MCTS_TEMPERATURE_THRESHOLD else MCTS_TEMPERATURE_LATE
        
        if temperature == 0:
            best_move = max(self.root.children.items(), key=lambda x: x[1].visit_count)[0]
        else:
            moves = list(self.root.children.keys())
            visit_counts = [child.visit_count for child in self.root.children.values()]
            visit_counts_temp = [count**(1/temperature) for count in visit_counts]
            probs = [count / sum(visit_counts_temp) for count in visit_counts_temp]
            best_move = np.random.choice(moves, p=probs)
        
        # ì •ì±… íƒ€ê²Ÿ ìƒì„±
        policy_target = torch.zeros(ACTION_SPACE_SIZE, dtype=torch.float32)
        total_visits = sum(child.visit_count for child in self.root.children.values())
        
        if total_visits > 0:
            for move, child in self.root.children.items():
                move_idx = move_to_policy_index(move, self.root.position.side)
                policy_target[move_idx] = child.visit_count / total_visits
        
        return best_move, policy_target

    def _wait_for_batch_response(self, request_id, resp_q, worker_id):
        """
        ë°°ì¹˜ ì‘ë‹µì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        - "root": ë‹¨ì¼ ì‘ë‹µ (policy, value)
        - "batch": ë°°ì¹˜ ì‘ë‹µ (policies_list, values_list)
        """
        while True:
            w_id, r_id, *response = resp_q.get()
            if w_id == worker_id and r_id == request_id:
                if request_id == "root":
                    # ë‹¨ì¼ ì‘ë‹µ
                    return response[0], response[1]  # policy, value
                elif request_id == "batch":
                    # ë°°ì¹˜ ì‘ë‹µ
                    return response[0], response[1]  # policies_list, values_list
            else:
                # ë‹¤ë¥¸ ìš”ì²­ ê²°ê³¼ëŠ” ë‹¤ì‹œ íì— ë„£ìŒ
                resp_q.put((w_id, r_id, *response))

    def _wait_for_response(self, request_id, resp_q, worker_id):
        """
        ì‹ ê²½ë§ í‰ê°€ ì‘ë‹µì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        """
        while True:
            w_id, r_id, policy, value = resp_q.get()
            if w_id == worker_id and r_id == request_id:
                return policy, value
            else:
                # ë‹¤ë¥¸ ìš”ì²­ ê²°ê³¼ëŠ” ë‹¤ì‹œ íì— ë„£ìŒ
                resp_q.put((w_id, r_id, policy, value))

