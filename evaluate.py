import torch
import torch.multiprocessing as mp
import time
import os

from ..core.position import parse_fen
from ..core.moves import generate_moves, make_move, get_move_uci, is_game_over, generate_legal_moves
from ..core.constants import start_position

from .neural_network import ChessNet
from .mcts import MCTS
from .selfplay import position_to_tensor # selfplayì—ì„œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì„í¬íŠ¸
from .config import EVAL_NUM_GAMES, EVAL_MCTS_SIMULATIONS, EVAL_WIN_THRESHOLD, EVAL_NUM_WORKERS, INSUFFICIENT_MATERIAL_CHECK_INTERVAL

# í‰ê°€ ì„¤ì • (AlphaZero ë…¼ë¬¸ ê¸°ì¤€)
EVAL_CONFIG = {
    'num_games': EVAL_NUM_GAMES,  # AlphaZero ë…¼ë¬¸: 400ê²Œì„
    'mcts_simulations': EVAL_MCTS_SIMULATIONS, # AlphaZero ì²´ìŠ¤: 800 ì‹œë®¬ë ˆì´ì…˜
    'c_puct': 1.25,  # í‰ê°€ì‹œì—ë„ ë™ì¼í•œ c_puct ì‚¬ìš©
    'win_threshold': EVAL_WIN_THRESHOLD,  # AlphaZero ë…¼ë¬¸: 55% ìŠ¹ë¥ ë¡œ ëª¨ë¸ êµì²´
    # í‰ê°€ ì‹œ ì™„ì „ ê²°ì •ë¡ ì  í”Œë ˆì´ (AlphaZero ë…¼ë¬¸)
    'temperature': 0.0,  # í‰ê°€ ì‹œ ì˜¨ë„ 0 (ì™„ì „ greedy)
    'dirichlet_noise': False,  # í‰ê°€ ì‹œ Dirichlet noise ë¹„í™œì„±í™” (ë…¼ë¬¸ ê¸°ì¤€)
    'add_exploration_noise': False  # í‰ê°€ ì‹œ íƒí—˜ ë…¸ì´ì¦ˆ ì—†ìŒ (deterministic play)
}

from .game_player import play_game

def evaluate_worker(worker_id, new_model_path, best_model_path, game_queue, result_q, request_q, response_q, gui_queue=None):
    """ë‘ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²Œì„ íì—ì„œ ë™ì ìœ¼ë¡œ ê²Œì„ì„ ê°€ì ¸ì™€ ì§„í–‰í•˜ëŠ” ì›Œì»¤ (GPU ê°€ì†)"""
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Evaluation worker {worker_id} using device: {device}")
    
    # ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)
    new_model = ChessNet()
    new_model.load_state_dict(torch.load(new_model_path, map_location=device))
    new_model.to(device)
    new_model.eval()

    best_model = ChessNet()
    best_model.load_state_dict(torch.load(best_model_path, map_location=device))
    best_model.to(device)
    best_model.eval()

    # ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    models = {
        'new': new_model,
        'best': best_model
    }
    
    # ê²Œì„ ì„¤ì • (AlphaZero ë…¼ë¬¸ ê¸°ì¤€ - ì™„ì „ ê²°ì •ë¡ ì  í‰ê°€)
    game_config = {
        'mode': 'evaluate',
        'device': device,
        'temperature': EVAL_CONFIG['temperature'],  # 0.0 - í‰ê°€ ì‹œ íƒìš•ì  ì„ íƒ
        'dirichlet_noise': EVAL_CONFIG['dirichlet_noise'],  # False - í‰ê°€ ì‹œ ë…¸ì´ì¦ˆ ë¹„í™œì„±í™”
        'mcts_simulations': EVAL_CONFIG['mcts_simulations'],  # í‰ê°€ìš© MCTS ì‹œë®¬ë ˆì´ì…˜ ìˆ˜
        'request_q': request_q,   # ì…€í”„í”Œë ˆì´ì™€ ë™ì¼í•œ ì¶”ë¡  ì„œë²„ ì‚¬ìš©
        'response_q': response_q, # ì…€í”„í”Œë ˆì´ì™€ ë™ì¼í•œ ì¶”ë¡  ì„œë²„ ì‚¬ìš©
        'max_moves': 200,
        'save_history': False
    }
    
    print(f"Evaluation worker {worker_id} started.")
    print(f"  - MCTS simulations: {game_config['mcts_simulations']}")
    print(f"  - Temperature: {game_config['temperature']}")
    print(f"  - Dirichlet noise: {game_config['dirichlet_noise']}")
    print(f"  - AlphaZero ë…¼ë¬¸: Deterministic play for evaluation")

    while True:
        try:
            # ê²Œì„ íì—ì„œ ê²Œì„ IDë¥¼ ê°€ì ¸ì˜´ (timeoutì„ ë‘ì–´ ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
            game_id = game_queue.get(timeout=1.0)
        except:
            # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ
            print(f"Evaluation worker {worker_id} finished - no more games")
            break
        
        print(f"Evaluation worker {worker_id} starting game {game_id}")

        # ê³µí†µ ê²Œì„ í”Œë ˆì´ í•¨ìˆ˜ ì‚¬ìš©
        result = play_game(worker_id, game_id, models, game_config, gui_queue)
        
        # ê²°ê³¼ íì— ì €ì¥
        result_q.put(result)

def run_evaluation(new_model_path, best_model_path, gui_queue=None):
    """í‰ê°€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜ (GPU ê°€ì† ë° GUI ì—°ë™)"""
    print("--- Starting Evaluation ---")
    print(f"New model: {new_model_path}")
    print(f"Best model: {best_model_path}")
    print(f"Games: {EVAL_CONFIG['num_games']}, Workers: {EVAL_NUM_WORKERS}")

    # ì¶”ë¡  ì„œë²„ë¥¼ ìœ„í•œ í ìƒì„± (ì…€í”„í”Œë ˆì´ì™€ ë™ì¼)
    from .stable_inference import stable_inference_server  # InferenceServer â†’ stable_inference_server
    from .config import INFERENCE_BATCH_SIZE, INFERENCE_TIMEOUT
    
    request_q = mp.Queue()
    response_q = mp.Queue()
    
    # ì¶”ë¡  ì„œë²„ ì‹œì‘ (stable_inference_server ì‚¬ìš©)
    model_path = new_model_path  # ì´ë¯¸ ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©
    stop_event = mp.Event()
    
    # stable_inference_server í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    inference_process = mp.Process(
        target=stable_inference_server,
        args=(model_path, torch.device("cuda" if torch.cuda.is_available() else "cpu"), 
              request_q, response_q, stop_event)
    )
    inference_process.start()
    
    # ê²Œì„ íì™€ ê²°ê³¼ í ìƒì„± (selfplayì™€ ë™ì¼í•œ ë°©ì‹)
    game_queue = mp.Queue()
    result_q = mp.Queue()
    
    # ê²Œì„ íì— ê²Œì„ IDë“¤ ì¶”ê°€
    for game_id in range(EVAL_CONFIG['num_games']):
        game_queue.put(game_id)

    # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë“¤ ì‹œì‘ (selfplayì™€ ë™ì¼í•œ ë™ì  í• ë‹¹ ë°©ì‹)
    processes = []
    print(f"ğŸ Starting evaluation with {EVAL_NUM_WORKERS} workers...")
    
    for i in range(EVAL_NUM_WORKERS):
        p = mp.Process(target=evaluate_worker, args=(i, new_model_path, best_model_path, game_queue, result_q, request_q, response_q, gui_queue))
        processes.append(p)
        p.start()
        time.sleep(0.1)  # ì›Œì»¤ ì‹œì‘ ê°„ê²©
    
    # ê²°ê³¼ ì§‘ê³„ (ìƒ‰ê¹”ë³„ í†µê³„ í¬í•¨) - ì›Œì»¤ ì¢…ë£Œ ì „ì— ë¨¼ì € ìˆ˜ì§‘
    new_model_wins = 0
    draws = 0
    total_games = 0
    new_white_wins = 0  # ìƒˆ ëª¨ë¸ì´ ë°±ìœ¼ë¡œ ì´ê¸´ íšŸìˆ˜
    new_black_wins = 0  # ìƒˆ ëª¨ë¸ì´ í‘ìœ¼ë¡œ ì´ê¸´ íšŸìˆ˜
    white_draws = 0     # ìƒˆ ëª¨ë¸ì´ ë°±ì¼ ë•Œ ë¬´ìŠ¹ë¶€
    black_draws = 0     # ìƒˆ ëª¨ë¸ì´ í‘ì¼ ë•Œ ë¬´ìŠ¹ë¶€
    
    print("\n--- Collecting Results ---")
    collected_results = []
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ ìˆ˜ì§‘ (ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ ìˆ˜ì§‘)
    while total_games < EVAL_CONFIG['num_games']:
        try:
            res = result_q.get(timeout=10.0)  # 10ì´ˆ timeout (ë” ì—¬ìœ ìˆê²Œ)
            collected_results.append(res)
            total_games += 1
            
            if res['winner'] == 'draw':
                draws += 1
                if res['new_model_color'] == 'white':
                    white_draws += 1
                else:
                    black_draws += 1
                print(f"Game {res['game_id']}: Draw (New model as {res['new_model_color']}, {res['move_count']} moves)")
            elif res['winner'] == res['new_model_color']:
                new_model_wins += 1
                if res['new_model_color'] == 'white':
                    new_white_wins += 1
                else:
                    new_black_wins += 1
                print(f"Game {res['game_id']}: New model wins as {res['new_model_color']} ({res['move_count']} moves)")
            else:
                print(f"Game {res['game_id']}: Best model wins (New model as {res['new_model_color']}, {res['move_count']} moves)")
                
        except Exception as e:
            print(f"Warning: Timeout or error collecting result: {e}")
            print(f"Collected {total_games} results so far, breaking...")
            break
    
    print(f"Collected {total_games} results out of {EVAL_CONFIG['num_games']} expected games")
    
    # ëª¨ë“  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ê°€ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸° (ê²°ê³¼ ìˆ˜ì§‘ í›„)
    print("Waiting for all workers to finish...")
    for i, p in enumerate(processes):
        p.join(timeout=30.0)  # 30ì´ˆ timeout ì¶”ê°€
        if p.is_alive():
            print(f"Warning: Worker {i} is still alive, terminating...")
            p.terminate()
            p.join(timeout=5.0)
    
    print("All workers finished.")
    
    # ì¶”ë¡  ì„œë²„ ì •ë¦¬ (stable_inference_server ë°©ì‹)
    print("Terminating inference server...")
    stop_event.set()
    inference_process.join(timeout=10.0)
    if inference_process.is_alive():
        print("Warning: Inference server still alive after terminate")
        inference_process.terminate()
    
    # ìµœì¢… ê²°ê³¼ ê³„ì‚°
    best_model_wins = total_games - new_model_wins - draws
    win_rate = (new_model_wins + 0.5 * draws) / total_games if total_games > 0 else 0.0
    
    # ìƒ‰ê¹”ë³„ ìŠ¹ë¥  ê³„ì‚° (ê³µì •ì„± í™•ì¸)
    white_games = total_games // 2
    black_games = total_games - white_games
    white_score = new_white_wins + 0.5 * white_draws
    black_score = new_black_wins + 0.5 * black_draws
    white_win_rate = white_score / white_games if white_games > 0 else 0.0
    black_win_rate = black_score / black_games if black_games > 0 else 0.0
    
    print(f"\n--- Evaluation Results (AlphaZero ë°©ì‹) ---")
    print(f"Total games: {total_games} (ë°± {white_games}íŒ, í‘ {black_games}íŒ)")
    print(f"New model wins: {new_model_wins} (ë°±ìœ¼ë¡œ {new_white_wins}ìŠ¹, í‘ìœ¼ë¡œ {new_black_wins}ìŠ¹)")
    print(f"Best model wins: {best_model_wins}")  
    print(f"Draws: {draws} (ë°±ìœ¼ë¡œ {white_draws}ë¬´, í‘ìœ¼ë¡œ {black_draws}ë¬´)")
    print(f"")
    print(f"ğŸ“Š ìƒ‰ê¹”ë³„ ì„±ëŠ¥:")
    print(f"   ë°±ë²ˆ ìŠ¹ë¥ : {white_win_rate:.2%} ({new_white_wins}ìŠ¹ {white_draws}ë¬´ {white_games-new_white_wins-white_draws}íŒ¨)")
    print(f"   í‘ë²ˆ ìŠ¹ë¥ : {black_win_rate:.2%} ({new_black_wins}ìŠ¹ {black_draws}ë¬´ {black_games-new_black_wins-black_draws}íŒ¨)")
    print(f"   ì „ì²´ ìŠ¹ë¥ : {win_rate:.2%} (ì„ê³„ê°’: {EVAL_CONFIG['win_threshold']:.1%})")
    print(f"")
    print(f"âš™ï¸  í‰ê°€ ì„¤ì •: MCTS {EVAL_CONFIG['mcts_simulations']}íšŒ, ì˜¨ë„={EVAL_CONFIG['temperature']}, ë””ë¦¬í´ë ˆ ë…¸ì´ì¦ˆ={EVAL_CONFIG['dirichlet_noise']}")
    print(f"   ğŸ“œ AlphaZero ë…¼ë¬¸ ê¸°ì¤€: ì™„ì „ ê²°ì •ë¡ ì  í‰ê°€ (deterministic play)")
    print(f"   ğŸ¯ ìŠ¹ë¥  ì„ê³„ê°’: {EVAL_CONFIG['win_threshold']:.1%} (ë…¼ë¬¸ ê¸°ì¤€: 55%)")

    if win_rate > EVAL_CONFIG['win_threshold']:
        print("âœ… New model is better. Updating best model.")
        return True
    else:
        print("âŒ New model is not better. Keeping old model.")
        return False

if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê°€ì§œ ëª¨ë¸ íŒŒì¼ ìƒì„±
    if not os.path.exists('models'):
        os.makedirs('models')
    torch.save(ChessNet().state_dict(), 'models/new_model_eval.pth')
    torch.save(ChessNet().state_dict(), 'models/best_model_eval.pth')
    
    run_evaluation('models/new_model_eval.pth', 'models/best_model_eval.pth')
